
# Multimodal Human Detection System using Deep Learning Methods ğŸš€

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-Framework-orange?logo=pytorch)
![Transformer](https://img.shields.io/badge/Model-DETR-brightgreen?logo=transformer)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

## ğŸ” Overview

This project presents a **Transformer-based human detection system** that integrates **RGB, Thermal, and Infrared (IR) imaging** for robust detection in diverse environmental conditions. Built using the DEtection TRansformer (DETR) model, the system improves detection accuracy in scenarios such as low-light, occlusion, and cluttered backgrounds.

### ğŸ‘¨â€ğŸ’» Developed By
- **Abijith T**
- Agney Suresh  
- Athulkrishna Dhananjayan  
*(Under the guidance of Dr. Sreelekshmi P S, Assistant Professor, ECE Dept., NSS College of Engineering)*

## ğŸ§  Key Features

- ğŸ” **Multimodal Input:** RGB, Thermal, and Infrared imaging
- âš™ï¸ **Advanced Preprocessing:** CLAHE, Histogram Equalization, Gaussian Filtering
- ğŸ§­ **Object Detection with DETR:** End-to-end transformer model with self-attention
- ğŸ”§ **Hyperparameter Tuning:** Implemented using Optuna framework
- ğŸ“Š **Model Evaluation:** mAP, IoU, GIoU, training/validation curves
- ğŸ†š **Comparative Analysis:** DETR vs CNN-based models (YOLO, Faster R-CNN)

## ğŸ“ Project Structure

```
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ RGB/
â”‚   â”œâ”€â”€ Thermal/
â”‚   â”œâ”€â”€ IR/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ detr_model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ loss_curves/
â”‚   â”œâ”€â”€ detections/
â”‚   â””â”€â”€ metrics/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Data Exploration.ipynb
â”‚   â””â”€â”€ Optuna_Tuning.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ“· Sample Visuals

| Raw Image | Preprocessed | Detection Output |
|-----------|--------------|------------------|
| ![rgb](results/sample_rgb.png) | ![clahe](results/sample_clahe.png) | ![detection](results/sample_detection.png) |

## ğŸ§° Tech Stack

- **Language:** Python 3.10
- **Frameworks/Libraries:** PyTorch, OpenCV, Matplotlib, Optuna
- **Model Architecture:** Detection Transformer (DETR)
- **Annotation Format:** COCO
- **Hardware:** Raspberry Pi + Thermal/IR Cameras

## ğŸ§ª Performance Metrics

| Modality        | IoU (%) | mAP (%) |
|----------------|---------|---------|
| RGB Only       | 58.3    | 61.2    |
| Thermal Only   | 60.1    | 63.0    |
| IR Only        | 57.4    | 60.0    |
| **Multimodal** | **72.5** | **76.8** |

## ğŸ“¦ Installation

```bash
git clone https://github.com/abijitht/multimodal-human-detection
cd multimodal-human-detection
pip install -r requirements.txt
```

## â–¶ï¸ Usage

```bash
# Training the model
python src/train.py --config configs/multimodal.yaml

# Evaluating the model
python src/evaluate.py --weights saved_models/detr_multimodal.pth
```

## ğŸ“š References

- [DETR: End-to-End Object Detection with Transformers (Facebook AI)](https://arxiv.org/abs/2005.12872)
- [Optuna Hyperparameter Optimization](https://optuna.org/)
- [OpenThermalPose Dataset](https://github.com/Geng-J/OpenThermalPose)

## ğŸ”— Connect with Me

ğŸ“« [abijitht.dev@gmail.com](mailto:abijitht.dev@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/abijitht/)  
ğŸ“¸ [Instagram](https://instagram.com/abijith_t)  
ğŸŒ [Portfolio (Coming Soon)]()

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
